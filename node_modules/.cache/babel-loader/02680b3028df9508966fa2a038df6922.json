{"ast":null,"code":"var _jsxFileName = \"/Users/wan/smartplug/src/App.js\";\nimport React from 'react';\nimport SpeechRecognition from 'react-speech-recognition';\nimport { PropTypes, Component } from 'react';\nimport logo from \"./logo.svg\";\nimport './App.css';\nconst propTypes = {\n  // Props injected by SpeechRecognition\n  transcript: PropTypes.string,\n  startListening: PropTypes.func,\n  stopListening: PropTypes.func,\n  browserSupportsSpeechRecognition: PropTypes.bool\n};\n\nclass Dictaphone extends Component {\n  constructor(props) {\n    super(props);\n\n    this.set = async command => {\n      this.setState({\n        command: command\n      }); // if (this.state.command === \"你好\")\n      // {\n      //   console.log(\"good job\")\n      // }\n    };\n\n    this.state = {\n      command: ''\n    };\n    this.set = this.set.bind(this);\n  }\n\n  componentWillMount() {\n    const {\n      recognition\n    } = this.props;\n    recognition.lang = 'zh-CN';\n  }\n\n  render() {\n    const {\n      transcript,\n      resetTranscript,\n      browserSupportsSpeechRecognition\n    } = this.props;\n\n    if (!browserSupportsSpeechRecognition) {\n      return null;\n    }\n\n    return /*#__PURE__*/React.createElement(\"div\", {\n      className: \"App\",\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 50,\n        columnNumber: 9\n      }\n    }, /*#__PURE__*/React.createElement(\"header\", {\n      className: \"App-header\",\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 51,\n        columnNumber: 11\n      }\n    }, /*#__PURE__*/React.createElement(\"img\", {\n      src: logo,\n      className: \"App-logo\",\n      alt: \"logo\",\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 52,\n        columnNumber: 13\n      }\n    }), /*#__PURE__*/React.createElement(\"p\", {\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 53,\n        columnNumber: 13\n      }\n    }, \"you can try it! \\u4F60\\u597D\"), /*#__PURE__*/React.createElement(\"button\", {\n      onClick: resetTranscript,\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 56,\n        columnNumber: 13\n      }\n    }, \"Reset\"), /*#__PURE__*/React.createElement(\"span\", {\n      __self: this,\n      __source: {\n        fileName: _jsxFileName,\n        lineNumber: 57,\n        columnNumber: 13\n      }\n    }, transcript)));\n  }\n\n}\n\nexport default SpeechRecognition(Dictaphone);","map":{"version":3,"sources":["/Users/wan/smartplug/src/App.js"],"names":["React","SpeechRecognition","PropTypes","Component","propTypes","transcript","string","startListening","func","stopListening","browserSupportsSpeechRecognition","bool","Dictaphone","constructor","props","set","command","setState","state","bind","componentWillMount","recognition","lang","render","resetTranscript","logo"],"mappings":";AAAA,OAAOA,KAAP,MAAkB,OAAlB;AACA,OAAOC,iBAAP,MAA8B,0BAA9B;AACA,SAASC,SAAT,EAAoBC,SAApB,QAAqC,OAArC;;AAEA,OAAO,WAAP;AAEA,MAAMC,SAAS,GAAG;AAChB;AACAC,EAAAA,UAAU,EAAEH,SAAS,CAACI,MAFN;AAGhBC,EAAAA,cAAc,EAAEL,SAAS,CAACM,IAHV;AAIhBC,EAAAA,aAAa,EAAEP,SAAS,CAACM,IAJT;AAKhBE,EAAAA,gCAAgC,EAAER,SAAS,CAACS;AAL5B,CAAlB;;AAOA,MAAMC,UAAN,SAAyBT,SAAzB,CAAmC;AACjCU,EAAAA,WAAW,CAACC,KAAD,EAAO;AAChB,UAAMA,KAAN;;AADgB,SAclBC,GAdkB,GAcZ,MAAOC,OAAP,IAAmB;AACvB,WAAKC,QAAL,CAAc;AACZD,QAAAA,OAAO,EAAEA;AADG,OAAd,EADuB,CAKvB;AACA;AACA;AACA;AACD,KAvBiB;;AAGhB,SAAKE,KAAL,GAAa;AACXF,MAAAA,OAAO,EAAK;AADD,KAAb;AAGA,SAAKD,GAAL,GAAS,KAAKA,GAAL,CAASI,IAAT,CAAc,IAAd,CAAT;AACD;;AACDC,EAAAA,kBAAkB,GAAG;AACnB,UAAM;AAACC,MAAAA;AAAD,QAAgB,KAAKP,KAA3B;AACAO,IAAAA,WAAW,CAACC,IAAZ,GAAmB,OAAnB;AACD;;AAgBDC,EAAAA,MAAM,GAAG;AACP,UAAM;AAAElB,MAAAA,UAAF;AAAcmB,MAAAA,eAAd;AAA+Bd,MAAAA;AAA/B,QAAoE,KAAKI,KAA/E;;AAEA,QAAI,CAACJ,gCAAL,EAAuC;AACrC,aAAO,IAAP;AACD;;AAED,wBACI;AAAK,MAAA,SAAS,EAAC,KAAf;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACE;AAAQ,MAAA,SAAS,EAAC,YAAlB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACE;AAAK,MAAA,GAAG,EAAEe,IAAV;AAAgB,MAAA,SAAS,EAAC,UAA1B;AAAqC,MAAA,GAAG,EAAC,MAAzC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MADF,eAEE;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sCAFF,eAKE;AAAQ,MAAA,OAAO,EAAED,eAAjB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,eALF,eAME;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,OAAOnB,UAAP,CANF,CADF,CADJ;AAaD;;AAhDgC;;AAmDnC,eAAeJ,iBAAiB,CAACW,UAAD,CAAhC","sourcesContent":["import React from 'react';\nimport SpeechRecognition from 'react-speech-recognition'\nimport { PropTypes, Component } from 'react'\nimport logo from './logo.svg';\nimport './App.css';\n\nconst propTypes = {\n  // Props injected by SpeechRecognition\n  transcript: PropTypes.string,\n  startListening: PropTypes.func,\n  stopListening: PropTypes.func,\n  browserSupportsSpeechRecognition: PropTypes.bool\n}\nclass Dictaphone extends Component {\n  constructor(props){\n    super(props)\n\n    this.state = {\n      command   : '',\n    };\n    this.set=this.set.bind(this);\n  }\n  componentWillMount() {\n    const {recognition} = this.props\n    recognition.lang = 'zh-CN'\n  }\n\n\n  set = async (command) => {\n    this.setState({\n      command: command\n    })\n\n    // if (this.state.command === \"你好\")\n    // {\n    //   console.log(\"good job\")\n    // }\n  }\n\n\n\n  render() {\n    const { transcript, resetTranscript, browserSupportsSpeechRecognition } = this.props\n    \n    if (!browserSupportsSpeechRecognition) {\n      return null\n    }\n\n    return (\n        <div className=\"App\">\n          <header className=\"App-header\">\n            <img src={logo} className=\"App-logo\" alt=\"logo\" />\n            <p>\n              you can try it! 你好\n            </p>\n            <button onClick={resetTranscript}>Reset</button>\n            <span>{transcript}</span>\n          </header>\n\n        </div>\n    )\n  }\n}\n\nexport default SpeechRecognition(Dictaphone)\n\n"]},"metadata":{},"sourceType":"module"}